{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681fc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ca084",
   "metadata": {},
   "source": [
    "##### **Initialize environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Taxi-v3\").env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba4819",
   "metadata": {},
   "source": [
    "##### **Q-agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a7ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to copy paste the same QAgent\n",
    "# definition in every notebook, don't you think?\n",
    "from src.q_agent import QAgent\n",
    "\n",
    "# hyper-parameters\n",
    "# RL problems are full of these hyper-parameters.\n",
    "# For the moment, trust me when I set these values.\n",
    "# We will later play with these and see how they impact learning.\n",
    "alphas = [0.01, 0.1, 1]\n",
    "gammas = [0.1, 0.6, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3082e844",
   "metadata": {},
   "source": [
    "##### **Training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.loops import train\n",
    "\n",
    "# exploration vs exploitation prob\n",
    "# let's start with a constant probability of 10%.\n",
    "epsilon = 0.1\n",
    "n_episodes = 1000\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for alpha in alphas:\n",
    "    for gamma in gammas:\n",
    "        \n",
    "        print(f'alpha: {alpha}, gamma: {gamma}')\n",
    "        agent = QAgent(env, alpha, gamma)\n",
    "        \n",
    "        _, timesteps, penalties = train(agent,\n",
    "                                        env,\n",
    "                                        n_episodes,\n",
    "                                        epsilon)\n",
    "        \n",
    "        # collect timesteps and penalties for this pair\n",
    "        # of hyper-parameters (alpha, gamma)\n",
    "        results_ = pd.DataFrame()\n",
    "        results_['timesteps'] = timesteps\n",
    "        results_['penalties'] = penalties\n",
    "        results_['alpha'] = alpha\n",
    "        results_['gamma'] = gamma\n",
    "        results = pd.concat([results, results_])\n",
    "\n",
    "# index -> episode\n",
    "results = results.reset_index().rename(\n",
    "    columns={'index': 'episode'})\n",
    "\n",
    "# add column with the 2 hyper-parameters\n",
    "results['hyperparameters'] = [\n",
    "    f'alpha={a}, gamma={g}'\n",
    "    for (a, g) in zip(results['alpha'], results['gamma'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63c43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 4)\n",
    "sns.lineplot(x='episode', y='timesteps',\n",
    "             hue='hyperparameters', data=results);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884acbe6",
   "metadata": {},
   "source": [
    "##### **Discarding alpha=0.01**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8980363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loops import train_many_runs\n",
    "\n",
    "alphas = [0.1, 1]\n",
    "gammas = [0.1, 0.6, 0.9]\n",
    "\n",
    "epsilon = 0.1\n",
    "n_episodes = 1000\n",
    "n_runs = 10\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for alpha in alphas:\n",
    "    for gamma in gammas:\n",
    "        \n",
    "        print(f'alpha: {alpha}, gamma: {gamma}')\n",
    "        agent = QAgent(env, alpha, gamma)\n",
    "        \n",
    "        timesteps, penalties = train_many_runs(agent,\n",
    "                                               env,\n",
    "                                               n_episodes,\n",
    "                                               epsilon,\n",
    "                                               n_runs)\n",
    "        \n",
    "        # collect timesteps and penalties for this pair of\n",
    "        # hyper-parameters (alpha, gamma)\n",
    "        results_ = pd.DataFrame()\n",
    "        results_['timesteps'] = timesteps\n",
    "        results_['penalties'] = penalties\n",
    "        results_['alpha'] = alpha\n",
    "        results_['gamma'] = gamma\n",
    "        results = pd.concat([results, results_])\n",
    "\n",
    "# index -> episode\n",
    "results = results.reset_index().rename(\n",
    "    columns={'index': 'episode'})\n",
    "\n",
    "results['hyperparameters'] = [\n",
    "    f'alpha={a}, gamma={g}'\n",
    "    for (a, g) in zip(results['alpha'], results['gamma'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17372af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 4)\n",
    "sns.lineplot(x='episode', y='timesteps', hue='hyperparameters', data=results);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddee197",
   "metadata": {},
   "source": [
    "##### **Is the current value of 10% the best?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "What about epsilon? Is the current value of 10% the best?\n",
    "# best hyper-parameters so far\n",
    "alpha = 1.0\n",
    "gamma = 0.9\n",
    "\n",
    "epsilons = [0.01, 0.10, 0.9]\n",
    "n_runs = 10\n",
    "n_episodes = 200\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for epsilon in epsilons:\n",
    "        \n",
    "    print(f'epsilon: {epsilon}')\n",
    "    agent = QAgent(env, alpha, gamma)\n",
    "\n",
    "    timesteps, penalties = train_many_runs(agent,\n",
    "                                           env,\n",
    "                                           n_episodes,\n",
    "                                           epsilon,\n",
    "                                           n_runs)\n",
    "\n",
    "    # collect timesteps and penalties for this pair of\n",
    "    # hyper-parameters (alpha, gamma)\n",
    "    results_ = pd.DataFrame()\n",
    "    results_['timesteps'] = timesteps\n",
    "    results_['penalties'] = penalties\n",
    "    results_['epsilon'] = epsilon\n",
    "    results = pd.concat([results, results_])\n",
    "\n",
    "# index -> episode\n",
    "results = results.reset_index().rename(columns={'index': 'episode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8)\n",
    "sns.lineplot(x='episode', y='timesteps', hue='epsilon', data=results)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(12, 8)\n",
    "sns.lineplot(x='episode', y='penalties', hue='epsilon', data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96f15e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
